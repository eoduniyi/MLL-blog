---
title: Week 19
description: Week 19
header: Week 19
---

# Cleaning up data pt. 2
So, instead of using R to go back and calculate summary statistics, Rebekah, my CREU partner actually developed some C Sharp code that scrapes all the transcripts, gets the lines with timestamps and then determines things like number of tokens, number of unique tokens, duration of speech within the session, etc.. Shouts out to her! Her work saved me. You can check out her blog [here](https://rebekahmanweiler.wixsite.com/rebekahmanweiler/cra-w-blog) for more details about the script.

Now, I can use the txt files she generated to create the associated audio segments:

```java
if totalNumberOfFiles >= 1
	for k = 1 : totalNumberOfFiles
		// Go through all those files
		thisFolder = allFileInfo(k).folder;
		thisBaseFileName = allFileInfo(k).name;
		fullFileName = fullfile(thisFolder, thisBaseFileName);

		// Open and read the transcript
		// Note: This converts the transript file to a text file
		fileText = fileread(fullFileName);
		NewFolder = strrep(thisBaseFileName, '.txt', '')

		// Create a directory to store segments
		mkdir(NewFolder)
		cd(NewFolder)

		// Get the location of the audio file associated with the transcript file
		audioLocation = strrep(strrep(fullFileName, '_', '/'), '.txt', '.wav');
		audioLocation = insertAfter(audioLocation,'Children','/0wav')

		// Read in the audio file
		[x,Fs] = audioread(audioLocation);

		// Note: Unicode Character 'BULLET': U+2022/char(8226) is not sufficient
		expr_TS = '[0-9]+_[0-9]+';

		// Get timestamps from transcripts
		matches = regexp(fileText, expr_TS,'match');

		// Get start and stop times from matches...
		for i = 1:length(matches)
			num = textscan(string(strrep(matches(i),'_', ' ')),'%f', 'Delimiter',' ');
			num = num2cell(permute(num{1},[2,1]));
			num = cell2mat(num);
			st = num(1); // start time
			et = num(2); // end time
			if(st == 0)
				st = st + 1;           
			end

			startTime = round((st/1000)*Fs); // segment start time
			endTime = round((et/1000)*Fs); // segment end time
			segment = x(startTime:endTime); // get audio segment from audio file

			// Generate name for output file
			i = num2str(i);
			i = insertBefore(i,i,'_');
			outputFileName = strcat(i,'.wav');
			outputFileName = strrep(thisBaseFileName,'.txt', outputFileName);

			// Output audio file
			audiowrite(outputFileName,segment,Fs);   
		end

		cd .. // go back up a directory
	end
end
```

For clarity, the above code generates a .wav file for each audio segment within the transcript.
Here is a plot for visualizing this process:

```java
// Read in audio file and generate plots for an audio file and a audio file segment
[x,Fs] = audioread(audioLocation);
[M,N] = size(x);
dt = 1/Fs;
t = dt*(0:M-1);
figure;
plot(t,x);
title('Audio Signal');
xlabel('Time (s)');
ylabel('Amplitude');
for k = 1:L
	idx = ( segments(k,1) < t )  &  ( t < segments(k,2) )  ;
	figure;
	plot(t(idx),x(idx));
	title('Audio Signal-Segment');
	xlabel('Time (s)');
	ylabel('Amplitude');
end
```

![audio signal](https://storage.googleapis.com/root-proposal-1246/CREU_DATA/week_19/audiosignal.png)
![audio signal segment](https://storage.googleapis.com/root-proposal-1246/CREU_DATA/week_19/audiosignalsegment.png)

The majority of code uses a combination of regular expression functions and audio tools. Turns out this was a conceptually easy problem, but difficult to get all the parts together. I was actually playing around with ffmpeg, trying to extract the audio segments of interest. It's actually pretty straightforward:

```java
$ ffmpeg -i alice1.wav -ss 0 -t 9.901 -acodec copy alice-segment1.wav
```
However, I'm very picky... I mean, I'm still trying to get comfortable with MATLAB again. Though, it would be good practice to make use of bash scripts. I don't think my MATLAB method is the most accurate way of getting the audio segments but I think it's a pretty good solution. Comparable to most methods.

Additionally, I think it's a good idea to analyze the audio segments for their signal-to-noise ratio (SNR). Signal-to-noise ratio is defined as the ratio of the power of a signal (meaningful information) and the power of background noise (unwanted signal).

<a href="https://www.codecogs.com/eqnedit.php?latex=SNR&space;=&space;\dfrac{P_{signal}}{P_{noise}}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?SNR&space;=&space;\dfrac{P_{signal}}{P_{noise}}" title="SNR = \dfrac{P_{signal}}{P_{noise}}" /></a>

That is, if the SNR across the corpus is low, then I think we have a problem. However, if the SNRs are reasonable values (or perhaps we can even throw away the files that have poor SNR), then the corpus is probably fine. This came out of realizing that the time stamps don't correspond to the start and stop time of words, but rather the duration of the entire utterance. For example, the first utterance in the alice.wav last from 0 to 9.9901 seconds. However, only one word is uttered, 'open', and it's at the end of the duration. Thus, there is more noise than signal in that 10 second clip. That's really bad for training.

As an example, we will calculate the SNR of the alice.wav file (this is the same file I have been using to generate the other graphs):

```java
// Calculate SNR
snr(segment)
```

![snr](https://storage.googleapis.com/root-proposal-1246/CREU_DATA/week_19/snr.png)

Cool! Super straightforward and MATLAB automatically generates a nice plot of the SNR. < -10 dB isn't very good, the closer it is to 0 is better. So, that might be an interesting analysis in of itself, but at the moment, I think it's more interesting that negative. I'll have to scrape through all the files to asses how SNRs are distributed across the corpus.

Best, <br />
EO
