---
title: Week 19
description: Week 19
header: Week 19
---

# Cleaning up data pt. 2
So, instead of using R to go back and calculate summary statistics, Rebekah, my CREU partner actually developed some C# code that scrapes all the transcripts, gets the lines with timestamps and then determines things like number of tokens, number of unique tokens, duration of speech within the session, etc.. Shouts out to her! Her work saved me. You can check out her blog [here](https://rebekahmanweiler.wixsite.com/rebekahmanweiler/cra-w-blog) for more details about the script.

Now, I can use the txt files she generated to create the associated audio segments:

```java
if totalNumberOfFiles >= 1
	for k = 1 : totalNumberOfFiles
		// Go through all those files
		thisFolder = allFileInfo(k).folder;
		thisBaseFileName = allFileInfo(k).name;
		fullFileName = fullfile(thisFolder, thisBaseFileName);

		// Open and read the transcript
		// Note: This converts the transript file to a text file
		fileText = fileread(fullFileName);
		NewFolder = strrep(thisBaseFileName, '.txt', '')

		// Create a directory to store segments
		mkdir(NewFolder)
		cd(NewFolder)

		// Get the location of the audio file associated with the transcript file
		audioLocation = strrep(strrep(fullFileName, '_', '/'), '.txt', '.wav');
		audioLocation = insertAfter(audioLocation,'Children','/0wav')

		// Read in the audio file
		[x,Fs] = audioread(audioLocation);

		// Note: Unicode Character 'BULLET': U+2022/char(8226) is not sufficient
		expr_TS = '[0-9]+_[0-9]+';

		// Get timestamps from transcripts
		matches = regexp(fileText, expr_TS,'match');

		// Get start and stop times from matches...
		for i = 1:length(matches)
			num = textscan(string(strrep(matches(i),'_', ' ')),'%f', 'Delimiter',' ');
			num = num2cell(permute(num{1},[2,1]));
			num = cell2mat(num);
			st = num(1); // start time in milliseconds
			et = num(2); // end time in milliseconds
			if(st == 0)
				st = st + 1;           
			end

			startTime = round((st/1000)*Fs); // segment starting frame
			endTime = round((et/1000)*Fs); // segment end time frame
			segment = x(startTime:endTime); // get audio segment from audio file

			// Generate name for output file
			i = num2str(i);
			i = insertBefore(i,i,'_');
			outputFileName = strcat(i,'.wav');
			outputFileName = strrep(thisBaseFileName,'.txt', outputFileName);

			// Output audio file
			audiowrite(outputFileName,segment,Fs);   
		end

		cd .. // go back up a directory
	end
end
```

For clarity, the above code generates a .wav file for each audio segment within the transcript.
Here is a plot for visualizing this process:

```java
// Read in audio file and generate plots for an audio file and a audio file segment
[x,Fs] = audioread(audioLocation);
[M,N] = size(x);
dt = 1/Fs;
t = dt*(0:M-1);
segments = xlsread('timestamps.xlsx','A1:B1'); // example uses an excel file that contain the timestamps
L = size(segments,1);

// Plot entire audio file
figure;
plot(t,x);
title('Audio Signal');
xlabel('Time (s)');
ylabel('Amplitude');

// Plot audio file segment
for k = 1:L
	idx = (segments(k,1) < t )  &  ( t < segments(k,2))  ;
	figure;
	plot(t(idx),x(idx));
	title('Audio Signal-Segment');
	xlabel('Time (s)');
	ylabel('Amplitude');
end
```

<b>MATLAB OUTPUT: full audio file</b>
![audio signal](https://storage.googleapis.com/root-proposal-1246/CREU_DATA/week_19/audiosignal.png)

<b>MATLAB OUTPUT: segmented audio file</b>
![audio signal segment](https://storage.googleapis.com/root-proposal-1246/CREU_DATA/week_19/audiosignalsegment.png)

The majority of code uses a combination of regular expression functions and audio tools. Turns out this was a conceptually easy problem, but difficult to get all the parts together. I was actually playing around with ffmpeg, trying to extract the audio segments of interest. It's actually pretty straightforward:

```java
$ ffmpeg -i alice1.wav -ss 0 -t 9.901 -acodec copy alice-segment1.wav
```
However, I'm very picky... I mean, I'm still trying to get comfortable with MATLAB again. Though, it would be good practice to make use of bash scripts. I don't think my MATLAB method is the most accurate way of getting the audio segments but I think it's a pretty good solution. Comparable to most methods.

Additionally, I think it's a good idea to analyze the audio segments for their signal-to-noise ratio (SNR). Signal-to-noise ratio is defined as the ratio of the power of a signal (meaningful information) and the power of background noise (unwanted signal).

<a href="https://www.codecogs.com/eqnedit.php?latex=SNR&space;=&space;\dfrac{P_{signal}}{P_{noise}}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?SNR&space;=&space;\dfrac{P_{signal}}{P_{noise}}" title="SNR = \dfrac{P_{signal}}{P_{noise}}" /></a>

Which means, if the SNR across the corpus is low, then I think we have a problem. However, if the SNRs are reasonable values (or perhaps we can even throw away the files that have poor SNRs), then the corpus is probably fine. This came out of realizing that the time stamps don't correspond to the start and stop time of words, but rather the duration of the entire utterance. For example, the first utterance in the alice1.wav last from 0 to 9.9901 seconds. However, only one word is uttered, 'open', and it's at the end of the duration. Thus, there is more noise than signal in that 10 second clip. In general, that could be problematic for training.

As an example, we will calculate the SNR of the alice1.wav file:

```java
// Calculate SNR
snr(segment)
```

![snr](https://storage.googleapis.com/root-proposal-1246/CREU_DATA/week_19/snr.png)

Cool! Super straightforward and MATLAB automatically generates a nice plot of the SNR.
Note: We typically get SNR in values of dB (logarithmic decibel):

<a href="https://www.codecogs.com/eqnedit.php?latex=\begin{align*}&space;SNR_{dB}&space;&=&space;10log_{10}\bigg(\dfrac{P_{signal}}{P_{noise}}\bigg)&space;\\&space;SNR_{dB}&space;&=&space;10log_{10}(P_{signal})&space;-&space;10log_{10}(P_{noise})&space;\\&space;SNR_{dB}&space;&&space;=&space;P_{signal,dB}&space;-&space;P_{noise,dB}&space;\end{align*}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\begin{align*}&space;SNR_{dB}&space;&=&space;10log_{10}\bigg(\dfrac{P_{signal}}{P_{noise}}\bigg)&space;\\&space;SNR_{dB}&space;&=&space;10log_{10}(P_{signal})&space;-&space;10log_{10}(P_{noise})&space;\\&space;SNR_{dB}&space;&&space;=&space;P_{signal,dB}&space;-&space;P_{noise,dB}&space;\end{align*}" title="\begin{align*} SNR_{dB} &= 10log_{10}\bigg(\dfrac{P_{signal}}{P_{noise}}\bigg) \\ SNR_{dB} &= 10log_{10}(P_{signal}) - 10log_{10}(P_{noise}) \\ SNR_{dB} & = P_{signal,dB} - P_{noise,dB} \end{align*}" /></a>

Kind of cool, I do think SNR will help explain some of the variation we get when we test our ASR system.


< -10 dB isn't very good (the closer it is to 0 is better), but it's not terrible. So, that might be an interesting analysis in of itself, but at the moment, I think it's more interesting that negative. I'll have to scrape through all the files to asses how SNRs are distributed across the corpus.

Best, <br />
EO
