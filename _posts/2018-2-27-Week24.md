---
title: Week 24
description: Week 24
header: Week 24
---

## Notes on interest and learning

This week I spent collecting the results of my LTASS experiments. I mainly focused on visualizing these results because soon it will be presentation season. In fact, one of the things I wanted to do better this year was visualizing results. I want them to be transparent and interesting. So, I'm shooting for something simple but profound!

Currently brainstorming ideas about how I can showcase speech recognition and highlight the relationship between speech recognition and language learning. Ultimately, I think this will do a couple of things for me:

1. <i>Reintroduce the goal of this project to myself</i>
2. <i>Have fun learning about new ways to visualize my data and results</i>
3. <i>Begin building the story of how and why I chose to model language learning (MLL) using these methods</i>

Because to me, the coolest part of research is coming up with creative ways to study and present an idea or set of views to people. These are frameworks (stories?) that could potentially transform the way people think about the world. I mean, from my point of view this is super difficult. And often it doesn't appear that glamorous. However, I know that's where I want to go with this.

### The role of a child's interest
What does it take for a child to learn (acquire) a language? Indeed, it is some contribution to the child's intuition or implicit knowledge about the world and their environment. For instance, while it is not ethical to subject people to feral child experiments, [Genie](https://en.wikipedia.org/wiki/Genie_(feral_child)) tells us a lot. So, assuming that children are in the appropriate  social and linguistic environment that supports their native tongue, what contributions from other humans are required for the child to acquire language.

There turns out to be a lot of interesting infancy and developmental psychology research that discusses such items. Here I won't attempt to unpack the decades of results from these fields, nor pretend to understand them. Instead, I want to point to [Trevarthen](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.475.9911&rep=rep1&type=pdf) ([1979](https://philpapers.org/rec/TRECAC-2)) where he describes how the <i>control</i> people share during typical conversations is the basis for showing how an infantâ€™s <i>consciousness</i> and <i>[intentionality](https://en.wikipedia.org/wiki/Intentionality]</i>)</i> can be used to instruct the parent in establishing consistent communication. That is, because there is a certain level of intelligence that the child displays and the parent  <i>recognizes</i>, they are willing to share control appropriately during the interaction. From there, parents can more easily become aligned with the interest of the child and their developmental needs. Essentially a long-term training session between parent (personal trainer) and child (developing individual). So in the end, the child has interest, and the parent becomes interested in the child and their interest allowing the child to become interested (more interested) in the parent and their interest. Quite the theory!

<b>tldr</b>; It takes time to master a language (or anything), but perhaps being interested is motivation or a force that propels us through progress.

### LTASS
I don't think I have been very clear about what exactly LTASS is trying to accomplish. This was partly because I hadn't understood it very until recently. So, this week I spent a bit more time explaining LTASS and associated concepts. Though, I suppose that its all in the name. Again, LTASS stands for the long-term average speech spectrum, and it provides a way to analyze voice. The analysis. So, LTASS can show us:

1. Abnormal acoustical patterns
2. Quality of voice in terms of pitch and volume

Hence, we're mainly interested in the average frequencies (spectrum) of a particular voice (speech). We don't know if the average spectrum of the VoxForge and CHILDES corpora are different, but if they are significantly different, then perhaps some of the variability in speech recognition performance can be attributed to their difference in the spectrum (or a combination of their spectra, SNR, and other acoustical measurements).

Conceptually, the LTASS methods looks like collecting all of the speech samples from some input signal that was sampled at some sampling rate (let's say 16kHz). Then, taking the FFT/periodogram at some resolution. The resolution can be calculated beforehand because it depends on the FFT length and sampling rate:

<a href="https://www.codecogs.com/eqnedit.php?latex=Bin&space;\&space;Resolution&space;=&space;\dfrac{F_s}{N}&space;\\&space;\\&space;\\&space;\mbox{Where}&space;\&space;N&space;\&space;\mbox{is&space;the&space;length&space;of&space;the}&space;\&space;FFT()" target="_blank"><img src="https://latex.codecogs.com/gif.latex?Bin&space;\&space;Resolution&space;=&space;\dfrac{F_s}{N}&space;\\&space;\\&space;\\&space;\mbox{Where}&space;\&space;N&space;\&space;\mbox{is&space;the&space;number&space;of&space;}&space;\&space;FFT()\&space; bins" title="Bin \ Resolution = \dfrac{F_s}{N} \\ \\ \\ \mbox{Where} \ N \ \mbox{is the number of the} \ FFT()" /></a>

So, let's say in MATLAB we collected 88000 samples:
```c
[input_file, Fs] = audioread('input_signal'); % -> 88000 x 1 vector of samples; Fs = 16000
FFTBins = length(input_file)/2; % ->  44000
```
The number of FFT bins we would have is half of the number of samples (see [Nyquist-Shannon sampling theorem](https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem)). So, if our input signal was sampled at 16 kHz and we collected 88000 samples, the resolution of each FFT bin would be:



<a href="https://www.codecogs.com/eqnedit.php?latex=\dfrac{16&space;\&space;\mbox{kHz}}{88000&space;\&space;\mbox{samples}}&space;\approx&space;\dfrac{0.182&space;\&space;\mbox{Hz}}{\mbox{bin}}\\" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\dfrac{16&space;\&space;\mbox{kHz}}{88000&space;\&space;\mbox{samples}}&space;\approx&space;\dfrac{0.182&space;\&space;\mbox{Hz}}{\mbox{bin}}\\" title="\dfrac{16 \ \mbox{kHz}}{88000 \ \mbox{samples}} \approx \dfrac{0.182 \ \mbox{Hz}}{\mbox{bin}}\\" /></a>

<b>or<b>

<a href="https://www.codecogs.com/eqnedit.php?latex=\dfrac{8&space;\&space;\mbox{kHz}}{44000&space;\&space;\mbox{FFT&space;bins}}&space;\approx&space;\dfrac{0.182&space;\&space;\mbox{Hz}}{\mbox{bin}}\\" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\dfrac{8&space;\&space;\mbox{kHz}}{44000&space;\&space;\mbox{FFT&space;bins}}&space;\approx&space;\dfrac{0.182&space;\&space;\mbox{Hz}}{\mbox{bin}}\\" title="\dfrac{8 \ \mbox{kHz}}{44000 \ \mbox{FFT bins}} \approx \dfrac{0.182 \ \mbox{Hz}}{\mbox{bin}}\\" /></a>

Now, imagine some curious child listening to their parent's voice and after every 15 minutes (900 seconds) the child takes note of all the frequencies present in that 15 minute chunk of adult speech. The child is brilliant, so this note taking happens almost instantaneously.

This is more or less how we're using LTASS. After every 15 minutes we collect the frequency content in the adult speech and characterize the average spectral density (periodogram).

In MATLAB this looks like:

```c
totalNumberOfFiles = length(childesDirectory.length);
totalDuration = 0;
AccumulatedSamples = [];
AccumulatedFreq = {};

if totalNumberOfFiles >= 1
  for k = 1 : totalNumberOfFiles
    % Go through all those files
    thisFolder = childesDirectory(k).folder;
    thisBaseFileName = childesDirectory(k).name;
    fullFileName = fullfile(thisFolder, thisBaseFileName);

    % Accumulate audio samples
    info = audioinfo(fullFileName);
    audioFileDuration = info.Duration;
    totalDuration = totalDuration + audioFileDuration;
    [input_file, Fs] = audioread(fullFileName);
    if(Fs ~= 16000)
      Fs = 16000;
      cd('Resampled');
      audiowrite(thisBaseFileName,input_file,Fs);
      [input_file,Fs] = audioread(thisBaseFileName);
      cd ..
    end
    AccumulatedSamples = cat(1,AccumulatedSamples,input_file); %

    % Get frequencies
    if(totalDuration >= 900 || k == totalNumberOfFiles)
      signal = AccumulatedSamples(:,1);
      ltass_psd = psd(spectrum.periodogram,signal,'Fs',Fs,'NFFT',length(signal));
      frq_data = ltass_psd.data;
      AccumulatedFreq = [AccumulatedFreq, {frq_data}];
      totalDuration = 0;
      AccumulatedSamples = [];
    end
end
```

In researching LTASS, I found some [SoundZone_Tools](https://github.com/JacobD10/SoundZone_Tools/blob/master/LTASS.m) by JacobD10. One of the tools is an LTASS function. Instead, we can use his method:

```c
.
.
.
  % Get frequencies
  if(totalDuration >= 900 || k == totalNumberOfFiles)
      [ltass_SZ, frqs] = LTASS(AccumulatedSamples,(Fs/(length(AccumulatedSamples))),Fs);
      totalDuration = 0;
      AccumulatedSamples = [];
  end
end
```


## Cleaning up my mess
I believe it's time to make functions out of all the data collection methods I've been using. I've been neglecting this, but I need to be more productive.






Best, <br />
EO
