---
title: Week 24
description: Week 24
header: Week 24
---

## The relationship between interest and learning
This week I spent collecting the results from the LTASS experiments. I especially focused on visualizing these results because soon it will be research season. In fact, one of the components I wanted to do better is visualizing these results in a interesting and clear way. So, I'm shooting for something simple but deep! Descriptive art pieces? I also spent time brainstorming interesting ways I can showcase speech recognition and highlight the relationship between speech recognition and language learning. Ultimately I did this because I think it will do a couple of things for me:

1. <i>Reintroduce the goal of this project to myself</i>
2. <i>Have fun learning about new ways to visualize my data and results</i>
3. <i>Begin building the story of how and why I chose to model language learning (MLL) using these methods</i>

Because to me, the coolest part of research is coming up with creative ways to present an idea or set of ideas to people. These are frameworks (stories?) that could potentially transform the way people think about the world. I mean, from my point of view this is super difficult. And often it doesn't appear that glamorous. However, I know that's where I want to go with this.

### The role of a child's interest
What does it take for a child to acquire (learn) a language? Certainly, it is some contribution of the child's intuition or implicit knowledge about the world and their environment. For instance, while it is not ethical to subject people to feral child experiments, [Genie](https://en.wikipedia.org/wiki/Genie_(feral_child)) tells us a lot. So, assuming that children are in the appropriate  social and linguistic environment that supports their native tongue, what contributions from other humans are required for the child to acquire language

There turns out to be a lot of interesting infancy and developmental psychology research that discusses such items. Here I won't attempt to unpack centuries of results from these fields, nor pretend to understand them. Instead, I want to point to [Trevarthen](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.475.9911&rep=rep1&type=pdf) ([1979](https://philpapers.org/rec/TRECAC-2)) where he describes how the <i>control</i> people share during typical conversations is the basis for showing how an infantâ€™s <i>consciousness</i> and <i>[intentionality](https://en.wikipedia.org/wiki/Intentionality]</i>) can be used to instruct the parent in establishing consistent communication. That is, because there is a certain level of intelligence that the child shows and the parent <i>recognizes</i>, they are willing to share control appropriately during interaction. From there, parents can more easily become aligned with the interest of the child and developmental needs, producing a sort of long-term training session. So in the end, the child has interest and the parent becomes interested in the child and their interest allowing the child to become interested (more interested) in the parent and their interest. Well! That's quite the theory.

<b>tldr</b>; <i>It takes time to learn a language, but perhaps being interested is motivation or a force that propells us through progress.</i>

## LTASS
I don't think I have been very clear about what exactly LTASS is trying to accomplish. This is partly because I hadn't really understood it very until recently. So, this week I spent a bit more time explaining LTASS and associated concepts. Though, I suppose that its all in the name. Again, LTASS stands for the long-term average speech spectrum and is provides a way to analyze voice. the analysis. So, LTASS can show us:

1. Abnormal acoustical patterns
2. Quality of voice in terms of pitch and volume

Hence, we're essentially interested in the average frequencies or spectrum of a particular voice (speech). We don't know if the average spectrum of the VoxForge and CHILDES corpora are different, but if they are significantly different, then perhaps some of the variability in performance can be attributed to their difference in spectrum (or a combination of their spectra, SNR, and other acoustical measurements).

Conceptually, the LTASS methods looks like collecting all of the speech samples from a signal that was sampled at some sampling rate (let's say 16kHz). Then, taking the FFT/Periodogram at some resolution. The resolution can actually be calculated before hand because it depends on the FFT length and sampling rate:

<a href="https://www.codecogs.com/eqnedit.php?latex=Bin&space;\&space;Resolution&space;=&space;\dfrac{F_s}{N}&space;\\&space;\\&space;\\&space;\mbox{Where}&space;\&space;N&space;\&space;\mbox{is&space;the&space;length&space;of&space;the}&space;\&space;FFT()" target="_blank"><img src="https://latex.codecogs.com/gif.latex?Bin&space;\&space;Resolution&space;=&space;\dfrac{F_s}{N}&space;\\&space;\\&space;\\&space;\mbox{Where}&space;\&space;N&space;\&space;\mbox{is&space;the&space;length&space;of&space;the}&space;\&space;FFT()" title="Bin \ Resolution = \dfrac{F_s}{N} \\ \\ \\ \mbox{Where} \ N \ \mbox{is the length of the} \ FFT()" /></a>

So, let's say in MATLAB we collected 88000 samples:
```c
[input_file, Fs] = audioread('input_signal'); % -> 88000 x 1 vector of samples; Fs = 16000
FFTBins = length(input_file)/2; % ->  44000
```
The number of FFT bins we would have is half of the number of samples (see [Nyquist-Shannon sampling theorem](https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem)). So, if our input signal was sampled at 16 kHz and we collected 88000 samples, the resolution of each FFT bin would be:



<a href="https://www.codecogs.com/eqnedit.php?latex=\dfrac{16&space;\&space;\mbox{kHz}}{88000&space;\&space;\mbox{samples}}&space;\approx&space;\dfrac{0.182&space;\&space;\mbox{Hz}}{\mbox{bin}}\\" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\dfrac{16&space;\&space;\mbox{kHz}}{88000&space;\&space;\mbox{samples}}&space;\approx&space;\dfrac{0.182&space;\&space;\mbox{Hz}}{\mbox{bin}}\\" title="\dfrac{16 \ \mbox{kHz}}{88000 \ \mbox{samples}} \approx \dfrac{0.182 \ \mbox{Hz}}{\mbox{bin}}\\" /></a>

<b>or<b>

<a href="https://www.codecogs.com/eqnedit.php?latex=\dfrac{8&space;\&space;\mbox{kHz}}{44000&space;\&space;\mbox{FFT&space;bins}}&space;\approx&space;\dfrac{0.182&space;\&space;\mbox{Hz}}{\mbox{bin}}\\" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\dfrac{8&space;\&space;\mbox{kHz}}{44000&space;\&space;\mbox{FFT&space;bins}}&space;\approx&space;\dfrac{0.182&space;\&space;\mbox{Hz}}{\mbox{bin}}\\" title="\dfrac{8 \ \mbox{kHz}}{44000 \ \mbox{FFT bins}} \approx \dfrac{0.182 \ \mbox{Hz}}{\mbox{bin}}\\" /></a>

Now, imagine some curious child listening to their parent's voice for some undetermined amount of time and after every 15 minutes (900 seconds) the child take note of all the frequencies present in that 15 minute chunk of adult speech. The child is brilliant, so this note taking happens almost instantaneously.

This is more or less how we're using LTASS. After every 15 minutes we collect the frequency content in the adult speech and characterize the average spectral density (periodogram).

In MATLAB this looks like:

```c
totalNumberOfFiles = length(childesDirectory.length);
totalDuration = 0;
AccumulatedSamples = [];
AccumulatedFreq = {};

if totalNumberOfFiles >= 1
  for k = 1 : totalNumberOfFiles
  % Go through all those files
  thisFolder = childesDirectory(k).folder;
  thisBaseFileName = childesDirectory(k).name;
  fullFileName = fullfile(thisFolder, thisBaseFileName);

  % Accumulate audio samples
  info = audioinfo(fullFileName);
  audioFileDuration = info.Duration;
  totalDuration = totalDuration + audioFileDuration; % Calculate total audio file duration
  [input_file, Fs] = audioread(fullFileName);
  AccumulatedSamples = cat(1,AccumulatedSamples,input_file); %

  % Get LTASS results
  if(totalDuration >= 900 || k == totalNumberOfFiles)
      ltass_psd = psd(spectrum.periodogram,signal,'Fs',Fs,'NFFT',length(signal));
      totalDuration = 0;
  end
end
```


## Cleaning up my mess
I believe it's time to make functions out of all the data collection methods I've been using. I've been neglecting this, but I need to be more productive. The pattern generating these results don't strike me as too difficult to manage, but I know I could always have clearer descriptions.






Best, <br />
EO
